# ML Prediction Service Configuration

## Environment Setup

This service requires environment variables to be configured. Follow these steps:

1. **Copy the example environment file:**
   ```bash
   cp .env.example .env
   ```

2. **Edit the `.env` file with your actual configuration:**

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `ENVIRONMENT` | `development` | Application environment |
| `SERVICE_NAME` | `ml-prediction-service` | Service name |
| `SERVICE_VERSION` | `1.0.0` | Service version |
| `HOST` | `0.0.0.0` | Host to bind the service |
| `PORT` | `8001` | Port to run the service |
| `CICIDS_MODEL_PATH` | `/app/src/models/rf_cicids2017_model.pkl` | Path to CICIDS model file |
| `LANL_MODEL_PATH` | `/app/src/models/isolation_forest_model.pkl` | Path to LANL model file |
| `MODELS_BASE_PATH` | `/app/src/models` | Base path for model files |
| `API_TITLE` | `ML Prediction Service` | FastAPI title |
| `API_DESCRIPTION` | `Microservice for machine learning risk predictions using CICIDS and LANL models` | FastAPI description |
| `ALLOWED_ORIGINS` | `*` | CORS allowed origins (comma-separated) |
| `ALLOWED_METHODS` | `GET,POST,PUT,DELETE` | CORS allowed methods (comma-separated) |
| `ALLOWED_HEADERS` | `*` | CORS allowed headers (comma-separated) |
| `LOG_LEVEL` | `INFO` | Logging level |
| `LOG_FORMAT` | `%(asctime)s - %(name)s - %(levelname)s - %(message)s` | Logging format |
| `MAX_PREDICTION_RETRIES` | `3` | Maximum prediction retry attempts |
| `PREDICTION_TIMEOUT` | `30` | Prediction timeout (seconds) |

## Model Requirements

The service requires trained ML models to be available:

1. **CICIDS Model**: Random Forest model for network traffic analysis
   - File: `rf_cicids2017_model.pkl`
   - Format: Scikit-learn pickle file

2. **LANL Model**: Isolation Forest model for user behavior analysis
   - File: `isolation_forest_model.pkl`
   - Format: Joblib bundle with model and encoders

## Security Notes

- **Never commit the `.env` file to version control**
- The `.env` file is included in `.gitignore`
- Only commit the `.env.example` file with placeholder values
- Keep model files secure and consider using volume mounts in Docker

## Docker Usage

When using Docker, you can:

1. Use the `.env` file (recommended for development)
2. Pass environment variables directly to Docker:
   ```bash
   docker run -e CICIDS_MODEL_PATH="/models/cicids.pkl" ml-prediction-service
   ```
3. Use Docker Compose with environment variables defined in `docker-compose.yml`

## API Endpoints

- `GET /health` - Health check
- `POST /api/v1/predict/cicids` - CICIDS model prediction
- `POST /api/v1/predict/lanl` - LANL model prediction
- `POST /api/v1/predict/combined` - Combined prediction
- `GET /api/v1/models` - List available models
- `GET /api/v1/models/{model_name}/info` - Get model information

## Architecture

The service follows a clean architecture pattern:

```
src/
├── config/          # Configuration management
├── interfaces/      # Abstract interfaces
├── services/        # Business logic
├── controllers/     # Request handling
├── api/            # API routes
└── models/         # Data models/schemas
```
